{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59378af0",
   "metadata": {},
   "source": [
    "## ðŸ“‘ Navigation\n",
    "\n",
    "**Part 1: Setup** â†’ Import Libraries, Load Data\n",
    "\n",
    "**Part 2: Distribution Analysis** â†’ Class Balance, Multi-Label Co-occurrence, Coverage\n",
    "\n",
    "**Part 3: Linguistic Analysis** â†’ Features, Signatures, Statistical Tests\n",
    "\n",
    "**Part 4: Vocabulary Analysis** â†’ TF-IDF, Overlap, Discriminative Terms\n",
    "\n",
    "**Part 5: Summary** â†’ Key Findings, Recommendations, Export\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc19f77",
   "metadata": {},
   "source": [
    "# Part 1: Setup & Data Loading\n",
    "## 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97051bee",
   "metadata": {},
   "source": [
    "## 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa946c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "DATA_PATH = \"arb copy.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTotal samples: {len(df):,}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9013d",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Class Distribution Analysis\n",
    "## 2.1 Target Label Distribution\n",
    "\n",
    "Quantifying class imbalance across all six polarization manifestation categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all six polarization manifestation types\n",
    "MANIFESTATION_TYPES = ['stereotype', 'vilification', 'dehumanization', 'extreme_language', 'lack_of_empathy', 'invalidation']\n",
    "\n",
    "# Calculate class distributions\n",
    "print(\"=\" * 70)\n",
    "print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "distribution_stats = {}\n",
    "for col in MANIFESTATION_TYPES:\n",
    "    positive_count = df[col].sum()\n",
    "    negative_count = len(df) - positive_count\n",
    "    positive_pct = (positive_count / len(df)) * 100\n",
    "    \n",
    "    distribution_stats[col] = {\n",
    "        'positive': positive_count,\n",
    "        'negative': negative_count,\n",
    "        'positive_pct': positive_pct,\n",
    "        'imbalance_ratio': negative_count / positive_count if positive_count > 0 else np.inf\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'â”€' * 70}\")\n",
    "    print(f\"ðŸ“Š {col.upper().replace('_', ' ')}\")\n",
    "    print(f\"{'â”€' * 70}\")\n",
    "    print(f\"  Positive samples: {positive_count:,} ({positive_pct:.2f}%)\")\n",
    "    print(f\"  Negative samples: {negative_count:,} ({100-positive_pct:.2f}%)\")\n",
    "    print(f\"  Imbalance ratio: 1:{distribution_stats[col]['imbalance_ratio']:.2f}\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame(distribution_stats).T\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\" * 70)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ada4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Class distribution comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "\n",
    "# 1. Bar chart comparing positive samples\n",
    "ax1 = axes[0, 0]\n",
    "positive_counts = [distribution_stats[col]['positive'] for col in MANIFESTATION_TYPES]\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#9b59b6', '#f39c12', '#e67e22']\n",
    "bars = ax1.bar([m.replace('_', '\\n') for m in MANIFESTATION_TYPES], positive_counts, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax1.set_title('Positive Sample Distribution Across Manifestation Types', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "ax1.set_xlabel('Manifestation Type', fontsize=12)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "for i, (bar, count) in enumerate(zip(bars, positive_counts)):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 20,\n",
    "            f'{count:,}\\n({distribution_stats[MANIFESTATION_TYPES[i]][\"positive_pct\"]:.1f}%)',\n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Stacked bar showing positive/negative split\n",
    "ax2 = axes[0, 1]\n",
    "positive_data = [distribution_stats[col]['positive'] for col in MANIFESTATION_TYPES]\n",
    "negative_data = [distribution_stats[col]['negative'] for col in MANIFESTATION_TYPES]\n",
    "x_pos = np.arange(len(MANIFESTATION_TYPES))\n",
    "ax2.bar(x_pos, positive_data, label='Positive', color='#e74c3c', alpha=0.8)\n",
    "ax2.bar(x_pos, negative_data, bottom=positive_data, label='Negative', color='#95a5a6', alpha=0.8)\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels([m.replace('_', '\\n') for m in MANIFESTATION_TYPES], fontsize=9)\n",
    "ax2.set_title('Positive vs Negative Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Count', fontsize=12)\n",
    "ax2.set_xlabel('Manifestation Type', fontsize=12)\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Imbalance ratio comparison\n",
    "ax3 = axes[1, 0]\n",
    "imbalance_ratios = [distribution_stats[col]['imbalance_ratio'] for col in MANIFESTATION_TYPES]\n",
    "bars = ax3.barh([m.replace('_', '\\n') for m in MANIFESTATION_TYPES], imbalance_ratios, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax3.set_title('Class Imbalance Ratio (Negative:Positive)', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Imbalance Ratio', fontsize=12)\n",
    "ax3.axvline(x=1, color='red', linestyle='--', linewidth=2, alpha=0.5, label='Balanced')\n",
    "for i, (bar, ratio) in enumerate(zip(bars, imbalance_ratios)):\n",
    "    width = bar.get_width()\n",
    "    ax3.text(width + 0.05, bar.get_y() + bar.get_height()/2.,\n",
    "            f'1:{ratio:.2f}', ha='left', va='center', fontweight='bold', fontsize=10)\n",
    "ax3.legend()\n",
    "ax3.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. Percentage distribution pie chart\n",
    "ax4 = axes[1, 1]\n",
    "positive_percentages = [distribution_stats[col]['positive_pct'] for col in MANIFESTATION_TYPES]\n",
    "labels = [m.replace('_', ' ').title() for m in MANIFESTATION_TYPES]\n",
    "wedges, texts, autotexts = ax4.pie(positive_percentages, labels=labels, \n",
    "                                     autopct='%1.1f%%', colors=colors, startangle=90,\n",
    "                                     explode=[0.05]*6, shadow=True)\n",
    "ax4.set_title('Relative Proportion of Positive Samples', fontsize=14, fontweight='bold')\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display recommended class weights for weighted loss\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RECOMMENDED CLASS WEIGHTS FOR WEIGHTED LOSS\")\n",
    "print(\"=\" * 70)\n",
    "for col in MANIFESTATION_TYPES:\n",
    "    pos_weight = len(df) / (2 * distribution_stats[col]['positive'])\n",
    "    neg_weight = len(df) / (2 * distribution_stats[col]['negative'])\n",
    "    print(f\"\\n{col.upper().replace('_', ' ')}:\")\n",
    "    print(f\"  Positive class weight: {pos_weight:.4f}\")\n",
    "    print(f\"  Negative class weight: {neg_weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928c1fe4",
   "metadata": {},
   "source": [
    "## 2.2 Multi-Label Co-occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1dd399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-label co-occurrence analysis\n",
    "print(\"=\" * 70)\n",
    "print(\"MULTI-LABEL CO-OCCURRENCE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Count samples with multiple labels\n",
    "df['label_count'] = df[MANIFESTATION_TYPES].sum(axis=1)\n",
    "\n",
    "print(\"\\nLabel Count Distribution:\")\n",
    "print(df['label_count'].value_counts().sort_index())\n",
    "\n",
    "# Pairwise co-occurrence\n",
    "print(\"\\n\" + \"â”€\" * 70)\n",
    "print(\"PAIRWISE CO-OCCURRENCE (Top 10 pairs)\")\n",
    "print(\"â”€\" * 70)\n",
    "\n",
    "from itertools import combinations\n",
    "co_occur_list = []\n",
    "for col1, col2 in combinations(MANIFESTATION_TYPES, 2):\n",
    "    co_occur = ((df[col1] == 1) & (df[col2] == 1)).sum()\n",
    "    co_occur_list.append((col1, col2, co_occur))\n",
    "\n",
    "co_occur_list.sort(key=lambda x: x[2], reverse=True)\n",
    "for col1, col2, count in co_occur_list[:10]:\n",
    "    print(f\"{col1.replace('_', ' ').title():20} âˆ© {col2.replace('_', ' ').title():20}: {count:5,} samples\")\n",
    "\n",
    "# Samples with all six labels\n",
    "all_six = df[MANIFESTATION_TYPES].apply(lambda row: all(row == 1), axis=1).sum()\n",
    "print(f\"\\nAll six labels: {all_six} samples\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Label count distribution\n",
    "ax1 = axes[0]\n",
    "label_dist = df['label_count'].value_counts().sort_index()\n",
    "ax1.bar(label_dist.index, label_dist.values, color='#9b59b6', alpha=0.8, edgecolor='black')\n",
    "ax1.set_title('Distribution of Label Counts per Sample', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Number of Labels', fontsize=12)\n",
    "ax1.set_ylabel('Sample Count', fontsize=12)\n",
    "for i, v in enumerate(label_dist.values):\n",
    "    ax1.text(label_dist.index[i], v + 20, str(v), ha='center', fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Co-occurrence heatmap\n",
    "ax2 = axes[1]\n",
    "co_occurrence_matrix = np.zeros((len(MANIFESTATION_TYPES), len(MANIFESTATION_TYPES)))\n",
    "for i, col1 in enumerate(MANIFESTATION_TYPES):\n",
    "    for j, col2 in enumerate(MANIFESTATION_TYPES):\n",
    "        if i == j:\n",
    "            co_occurrence_matrix[i, j] = distribution_stats[col1]['positive']\n",
    "        else:\n",
    "            co_occurrence_matrix[i, j] = ((df[col1] == 1) & (df[col2] == 1)).sum()\n",
    "\n",
    "labels = [c.replace('_', '\\n').title() for c in MANIFESTATION_TYPES]\n",
    "sns.heatmap(co_occurrence_matrix, annot=True, fmt='.0f', cmap='YlOrRd', \n",
    "            xticklabels=labels,\n",
    "            yticklabels=labels,\n",
    "            cbar_kws={'label': 'Co-occurrence Count'}, ax=ax2)\n",
    "ax2.set_title('Label Co-occurrence Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2677068a",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Linguistic Analysis\n",
    "## 3.1 Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction functions\n",
    "def extract_linguistic_features(text):\n",
    "    \"\"\"Extract linguistic features from Arabic text.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return {\n",
    "            'char_length': 0,\n",
    "            'word_count': 0,\n",
    "            'latin_chars': 0,\n",
    "            'latin_char_ratio': 0,\n",
    "            'digits': 0,\n",
    "            'digit_ratio': 0,\n",
    "            'has_multilingual': 0\n",
    "        }\n",
    "    \n",
    "    text_str = str(text)\n",
    "    char_length = len(text_str)\n",
    "    word_count = len(text_str.split())\n",
    "    \n",
    "    # Count Latin characters (A-Z, a-z)\n",
    "    latin_chars = len(re.findall(r'[A-Za-z]', text_str))\n",
    "    latin_char_ratio = latin_chars / char_length if char_length > 0 else 0\n",
    "    \n",
    "    # Count Western digits\n",
    "    digits = len(re.findall(r'[0-9]', text_str))\n",
    "    digit_ratio = digits / char_length if char_length > 0 else 0\n",
    "    \n",
    "    # Has multilingual elements (code-switching indicator)\n",
    "    has_multilingual = 1 if (latin_chars > 0 or digits > 0) else 0\n",
    "    \n",
    "    return {\n",
    "        'char_length': char_length,\n",
    "        'word_count': word_count,\n",
    "        'latin_chars': latin_chars,\n",
    "        'latin_char_ratio': latin_char_ratio,\n",
    "        'digits': digits,\n",
    "        'digit_ratio': digit_ratio,\n",
    "        'has_multilingual': has_multilingual\n",
    "    }\n",
    "\n",
    "# Extract features for all texts\n",
    "print(\"Extracting linguistic features...\")\n",
    "features = df['text'].apply(extract_linguistic_features)\n",
    "feature_df = pd.DataFrame(features.tolist())\n",
    "\n",
    "# Merge with original dataframe\n",
    "df_analysis = pd.concat([df, feature_df], axis=1)\n",
    "\n",
    "print(\"âœ“ Feature extraction complete\")\n",
    "print(f\"\\nFeatures extracted: {list(feature_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486950a",
   "metadata": {},
   "source": [
    "## 3.2 Linguistic Signatures by Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97deb27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison across manifestation types\n",
    "print(\"=\" * 70)\n",
    "print(\"LINGUISTIC SIGNATURES BY MANIFESTATION TYPE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "linguistic_features = ['char_length', 'word_count', 'latin_char_ratio', 'digit_ratio', 'has_multilingual']\n",
    "\n",
    "comparison_stats = {}\n",
    "for manif_type in MANIFESTATION_TYPES:\n",
    "    print(f\"\\n{'â•' * 70}\")\n",
    "    print(f\"ðŸ“ {manif_type.upper().replace('_', ' ')}\")\n",
    "    print(f\"{'â•' * 70}\")\n",
    "    \n",
    "    positive_samples = df_analysis[df_analysis[manif_type] == 1]\n",
    "    negative_samples = df_analysis[df_analysis[manif_type] == 0]\n",
    "    \n",
    "    comparison_stats[manif_type] = {'positive': {}, 'negative': {}}\n",
    "    \n",
    "    for feature in linguistic_features:\n",
    "        pos_mean = positive_samples[feature].mean()\n",
    "        neg_mean = negative_samples[feature].mean()\n",
    "        pos_std = positive_samples[feature].std()\n",
    "        neg_std = negative_samples[feature].std()\n",
    "        \n",
    "        comparison_stats[manif_type]['positive'][feature] = {'mean': pos_mean, 'std': pos_std}\n",
    "        comparison_stats[manif_type]['negative'][feature] = {'mean': neg_mean, 'std': neg_std}\n",
    "        \n",
    "        print(f\"\\n  {feature.replace('_', ' ').title()}:\")\n",
    "        print(f\"    Positive: Î¼={pos_mean:.2f}, Ïƒ={pos_std:.2f}\")\n",
    "        print(f\"    Negative: Î¼={neg_mean:.2f}, Ïƒ={neg_std:.2f}\")\n",
    "        diff_pct = ((pos_mean - neg_mean) / neg_mean * 100) if neg_mean != 0 else 0\n",
    "        print(f\"    Difference: {pos_mean - neg_mean:+.2f} ({diff_pct:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba438dc",
   "metadata": {},
   "source": [
    "## 3.3 Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a475007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive visualization of linguistic signatures\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Linguistic Signature Analysis Across Manifestation Types', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "colors_manif = {m: c for m, c in zip(MANIFESTATION_TYPES, colors)}\n",
    "\n",
    "# 1. Mean Character Length Comparison\n",
    "ax1 = axes[0, 0]\n",
    "pos_means = [comparison_stats[mt]['positive']['char_length']['mean'] for mt in MANIFESTATION_TYPES]\n",
    "neg_means = [comparison_stats[mt]['negative']['char_length']['mean'] for mt in MANIFESTATION_TYPES]\n",
    "x = np.arange(len(MANIFESTATION_TYPES))\n",
    "width = 0.35\n",
    "ax1.bar(x - width/2, pos_means, width, label='Positive', color='#e74c3c', alpha=0.8)\n",
    "ax1.bar(x + width/2, neg_means, width, label='Negative', color='#95a5a6', alpha=0.8)\n",
    "ax1.set_title('Mean Character Length by Class', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel('Mean Character Length', fontsize=11)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([mt.replace('_', '\\n').title() for mt in MANIFESTATION_TYPES], fontsize=9)\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Mean Word Count Comparison\n",
    "ax2 = axes[0, 1]\n",
    "pos_means = [comparison_stats[mt]['positive']['word_count']['mean'] for mt in MANIFESTATION_TYPES]\n",
    "neg_means = [comparison_stats[mt]['negative']['word_count']['mean'] for mt in MANIFESTATION_TYPES]\n",
    "ax2.bar(x - width/2, pos_means, width, label='Positive', color='#3498db', alpha=0.8)\n",
    "ax2.bar(x + width/2, neg_means, width, label='Negative', color='#95a5a6', alpha=0.8)\n",
    "ax2.set_title('Mean Word Count by Class', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylabel('Mean Word Count', fontsize=11)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels([mt.replace('_', '\\n').title() for mt in MANIFESTATION_TYPES], fontsize=9)\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Multilingual Element Presence\n",
    "ax3 = axes[1, 0]\n",
    "multilingual_pct = []\n",
    "for manif_type in MANIFESTATION_TYPES:\n",
    "    positive_samples = df_analysis[df_analysis[manif_type] == 1]\n",
    "    pct = (positive_samples['has_multilingual'].sum() / len(positive_samples)) * 100 if len(positive_samples) > 0 else 0\n",
    "    multilingual_pct.append(pct)\n",
    "bars = ax3.bar([mt.replace('_', '\\n').title() for mt in MANIFESTATION_TYPES], multilingual_pct, \n",
    "               color=[colors_manif[mt] for mt in MANIFESTATION_TYPES], \n",
    "               alpha=0.8, edgecolor='black')\n",
    "ax3.set_title('Multilingual Element Presence (% of Positive Samples)', fontsize=13, fontweight='bold')\n",
    "ax3.set_ylabel('Percentage (%)', fontsize=11)\n",
    "ax3.set_xlabel('Manifestation Type', fontsize=11)\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "for bar, pct in zip(bars, multilingual_pct):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "            f'{pct:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Latin Character Ratio Comparison\n",
    "ax4 = axes[1, 1]\n",
    "pos_means = [comparison_stats[mt]['positive']['latin_char_ratio']['mean'] * 100 for mt in MANIFESTATION_TYPES]\n",
    "neg_means = [comparison_stats[mt]['negative']['latin_char_ratio']['mean'] * 100 for mt in MANIFESTATION_TYPES]\n",
    "ax4.bar(x - width/2, pos_means, width, label='Positive', color='#2ecc71', alpha=0.8)\n",
    "ax4.bar(x + width/2, neg_means, width, label='Negative', color='#95a5a6', alpha=0.8)\n",
    "ax4.set_title('Latin Character Ratio (Code-Switching Indicator)', fontsize=13, fontweight='bold')\n",
    "ax4.set_ylabel('Latin Chars (% of total)', fontsize=11)\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels([mt.replace('_', '\\n').title() for mt in MANIFESTATION_TYPES], fontsize=9)\n",
    "ax4.legend()\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff61d07",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Vocabulary Analysis  \n",
    "## 4.1 TF-IDF: Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0cc717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for TF-IDF analysis\n",
    "def get_class_texts(df, class_name):\n",
    "    \"\"\"Extract texts for a specific class.\"\"\"\n",
    "    return df[df[class_name] == 1]['text'].dropna().astype(str).tolist()\n",
    "\n",
    "# Extract texts for each manifestation type\n",
    "class_texts = {}\n",
    "for manif_type in MANIFESTATION_TYPES:\n",
    "    class_texts[manif_type] = get_class_texts(df_analysis, manif_type)\n",
    "    print(f\"{manif_type.replace('_', ' ').title()}: {len(class_texts[manif_type])} texts\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TF-IDF ANALYSIS: TOP DISCRIMINATIVE UNIGRAMS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize TF-IDF vectorizer for unigrams\n",
    "tfidf_unigram = TfidfVectorizer(\n",
    "    max_features=100,\n",
    "    ngram_range=(1, 1),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "unigram_results = {}\n",
    "\n",
    "for manif_type in MANIFESTATION_TYPES:\n",
    "    print(f\"\\n{'â•' * 70}\")\n",
    "    print(f\"ðŸ” {manif_type.upper().replace('_', ' ')} - TOP 20 UNIGRAMS\")\n",
    "    print(f\"{'â•' * 70}\")\n",
    "    \n",
    "    if len(class_texts[manif_type]) > 0:\n",
    "        # Fit TF-IDF\n",
    "        tfidf_matrix = tfidf_unigram.fit_transform(class_texts[manif_type])\n",
    "        feature_names = tfidf_unigram.get_feature_names_out()\n",
    "        \n",
    "        # Calculate mean TF-IDF scores\n",
    "        mean_tfidf = np.asarray(tfidf_matrix.mean(axis=0)).flatten()\n",
    "        \n",
    "        # Get top words\n",
    "        top_indices = mean_tfidf.argsort()[-20:][::-1]\n",
    "        top_words = [(feature_names[i], mean_tfidf[i]) for i in top_indices]\n",
    "        \n",
    "        unigram_results[manif_type] = top_words\n",
    "        \n",
    "        # Display results\n",
    "        for rank, (word, score) in enumerate(top_words, 1):\n",
    "            print(f\"{rank:2d}. {word:30s} (TF-IDF: {score:.4f}\")\n",
    "    else:\n",
    "        print(\"  No samples found for this manifestation type\")\n",
    "        unigram_results[manif_type] = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb289bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top discriminative words\n",
    "fig, axes = plt.subplots(2, 3, figsize=(22, 12))\n",
    "fig.suptitle('Top 15 Discriminative Unigrams by Manifestation Type (TF-IDF)', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# Flatten axes for easier iteration\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for idx, manif_type in enumerate(MANIFESTATION_TYPES):\n",
    "    ax = axes_flat[idx]\n",
    "    \n",
    "    if len(unigram_results[manif_type]) > 0:\n",
    "        # Get top 15 words\n",
    "        top_15 = unigram_results[manif_type][:15]\n",
    "        words = [w[0] for w in top_15]\n",
    "        scores = [w[1] for w in top_15]\n",
    "        \n",
    "        # Create horizontal bar plot\n",
    "        y_pos = np.arange(len(words))\n",
    "        ax.barh(y_pos, scores, color=colors_manif[manif_type], alpha=0.8, edgecolor='black')\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(words, fontsize=9)\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel('TF-IDF Score', fontsize=11)\n",
    "        ax.set_title(f'{manif_type.upper().replace(\"_\", \" \")}', fontsize=12, fontweight='bold')\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'No data', ha='center', va='center', fontsize=14)\n",
    "        ax.set_title(f'{manif_type.upper().replace(\"_\", \" \")}', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81094c1b",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Summary & Recommendations\n",
    "## 5.1 Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary report\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPREHENSIVE EDA SUMMARY REPORT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary_report = f\"\"\"\n",
    "Dataset: arb copy.csv\n",
    "Total Samples: {len(df):,}\n",
    "\n",
    "CLASS DISTRIBUTION:\n",
    "{'â”€' * 70}\n",
    "\"\"\"\n",
    "\n",
    "for manif_type in MANIFESTATION_TYPES:\n",
    "    stats = distribution_stats[manif_type]\n",
    "    summary_report += f\"\"\"\n",
    "{manif_type.upper().replace('_', ' ')}:\n",
    "  Positive: {stats['positive']:,} ({stats['positive_pct']:.2f}%)\n",
    "  Negative: {stats['negative']:,} ({100-stats['positive_pct']:.2f}%)\n",
    "  Imbalance: 1:{stats['imbalance_ratio']:.2f}\n",
    "\"\"\"\n",
    "\n",
    "summary_report += f\"\"\"\n",
    "LINGUISTIC SIGNATURES (Positive Samples):\n",
    "{'â”€' * 70}\n",
    "\"\"\"\n",
    "\n",
    "for manif_type in MANIFESTATION_TYPES:\n",
    "    stats = comparison_stats[manif_type]['positive']\n",
    "    summary_report += f\"\"\"\n",
    "{manif_type.upper().replace('_', ' ')}:\n",
    "  Avg Character Length: {stats['char_length']['mean']:.1f} Â± {stats['char_length']['std']:.1f}\n",
    "  Avg Word Count: {stats['word_count']['mean']:.1f} Â± {stats['word_count']['std']:.1f}\n",
    "  Latin Char Ratio: {stats['latin_char_ratio']['mean']*100:.2f}%\n",
    "  Multilingual Presence: {stats['has_multilingual']['mean']*100:.1f}%\n",
    "\"\"\"\n",
    "\n",
    "summary_report += f\"\"\"\n",
    "TOP 5 DISCRIMINATIVE WORDS:\n",
    "{'â”€' * 70}\n",
    "\"\"\"\n",
    "\n",
    "for manif_type in MANIFESTATION_TYPES:\n",
    "    if len(unigram_results[manif_type]) >= 5:\n",
    "        top_5 = [w[0] for w in unigram_results[manif_type][:5]]\n",
    "        summary_report += f\"\\n{manif_type.upper().replace('_', ' ')}: {', '.join(top_5)}\"\n",
    "    else:\n",
    "        summary_report += f\"\\n{manif_type.upper().replace('_', ' ')}: [Insufficient data]\"\n",
    "\n",
    "summary_report += \"\\n\\n\" + \"=\" * 70\n",
    "\n",
    "print(summary_report)\n",
    "\n",
    "# Save report to file\n",
    "with open('EDA_Polarization_Manifestations_Report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(\"\\nâœ“ Summary report saved to 'EDA_Polarization_Manifestations_Report.txt'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“Š EDA COMPLETE - All analyses finished!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
