\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{polar-semeval-2026}
\citation{vasist2023polarizing}
\citation{farghaly2009arabic}
\citation{abdulmageed2021arbert,alshenafi2024rasid}
\citation{antoun2021aragpt2,alhariri2024smash}
\citation{obeid2020cameltools}
\citation{ridnik2021asl}
\HyPL@Entry{0<</S/D>>}
\xpglanginauxtrue 
\selectlanguage *{english}
\@writefile{toc}{\selectlanguage *{english}}
\xpglanginauxfalse 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{1}{section.2}\protected@file@percent }
\citation{polar-semeval-2026}
\citation{Shammari2007}
\citation{obeid2020cameltools}
\citation{arapola2026github}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Task Definition and Dataset}{2}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Exploratory Data Analysis}{2}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Preprocessing and Feature Engineering}{2}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Basic vs.\ Advanced Preprocessing}{2}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Basic preprocessing (used in best models).}{2}{section*.1}\protected@file@percent }
\citation{obeid2020cameltools}
\@writefile{toc}{\contentsline {paragraph}{Advanced preprocessing (tested, then discarded for final models).}{3}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Feature Engineering}{3}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Model Selection and Training Approaches}{3}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Subtask 1: Binary Polarization Detection}{3}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Training configuration.}{3}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Morphological feature exploration.}{3}{section*.4}\protected@file@percent }
\citation{antoun2021aragpt2}
\citation{ridnik2021asl}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Subtask 2: Multi-label Polarization Type}{4}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Prompt-based baseline.}{4}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Best system: MARBERTv2 + ASL + snapshot ensemble + stacking + thresholds.}{4}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Training configuration.}{5}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Subtask 3: Multi-label Manifestations}{5}{subsubsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Hardware.}{6}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{6}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Subtask 1}{6}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Subtask\nobreakspace  {}1 internal validation performance (macro-averaged). Values are computed from fold-wise classification reports.}}{6}{table.1}\protected@file@percent }
\newlabel{tab:subtask1_results}{{1}{6}{Subtask~1 internal validation performance (macro-averaged). Values are computed from fold-wise classification reports}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Subtask 2}{6}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Subtask\nobreakspace  {}2 per-label validation metrics and tuned thresholds from \texttt  {Final\_subtask2.ipynb}.}}{6}{table.2}\protected@file@percent }
\newlabel{tab:subtask2_perlabel}{{2}{6}{Subtask~2 per-label validation metrics and tuned thresholds from \texttt {Final\_subtask2.ipynb}}{table.2}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Subtask\nobreakspace  {}2 overall validation metrics.}}{6}{table.3}\protected@file@percent }
\newlabel{tab:subtask2_overall}{{3}{6}{Subtask~2 overall validation metrics}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Subtask 3}{6}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{7}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Dataset selection and impact.}{7}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Selection of approach: advantages and disadvantages.}{7}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Comparison to existing systems.}{7}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Morphological features and hybrid ensembles.}{7}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Preprocessing trade-offs.}{7}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Why ensembling helped.}{7}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Limitations of the proposed system.}{7}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Potential improvements with more time and resources.}{8}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{8}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Individual Contributions}{8}{section.7}\protected@file@percent }
\bibstyle{acl_natbib}
\bibcite{abdulmageed2021arbert}{{1}{2021}{{Abdul-Mageed et~al.}}{{}}}
\bibcite{alshenafi2024rasid}{{2}{2024}{{AlShenaifi et~al.}}{{}}}
\bibcite{alhariri2024smash}{{3}{2024}{{Al~Hariri and Abu~Farha}}{{}}}
\bibcite{antoun2021aragpt2}{{4}{2021}{{Antoun et~al.}}{{}}}
\bibcite{farghaly2009arabic}{{5}{2009}{{Farghaly and Shaalan}}{{}}}
\bibcite{obeid2020cameltools}{{6}{2020}{{Obeid et~al.}}{{}}}
\bibcite{polar-semeval-2026}{{7}{2025}{{POLAR @ SemEval}}{{}}}
\bibcite{ridnik2021asl}{{8}{2021}{{Ridnik et~al.}}{{}}}
\bibcite{vasist2023polarizing}{{9}{2023}{{Vasist et~al.}}{{}}}
\bibcite{Shammari2007}{{10}{2007}{{Al-Shammari}}{{}}}
\bibcite{arapola2026github}{{11}{2026}{{Ma et~al.}}{{}}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Label distribution for Subtask\nobreakspace  {}1 (ARB training).}}{10}{figure.1}\protected@file@percent }
\newlabel{fig:label_dist_bar}{{1}{10}{Label distribution for Subtask~1 (ARB training)}{figure.1}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Text length and word count distributions; label-wise comparisons.}}{10}{figure.2}\protected@file@percent }
\newlabel{fig:text_length_dist}{{2}{10}{Text length and word count distributions; label-wise comparisons}{figure.2}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Code-switching indicators: Latin characters and digit variants.}}{11}{figure.3}\protected@file@percent }
\newlabel{fig:latin_presence}{{3}{11}{Code-switching indicators: Latin characters and digit variants}{figure.3}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces URLs, mentions, and hashtags by label.}}{11}{figure.4}\protected@file@percent }
\newlabel{fig:mention_presence}{{4}{11}{URLs, mentions, and hashtags by label}{figure.4}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Emoji presence and counts by label.}}{11}{figure.5}\protected@file@percent }
\newlabel{fig:emoji_presence}{{5}{11}{Emoji presence and counts by label}{figure.5}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Original vs.\ basic vs.\ advanced preprocessing outputs (advanced includes clitic segmentation).}}{12}{figure.6}\protected@file@percent }
\newlabel{fig:preprocessing_comparison}{{6}{12}{Original vs.\ basic vs.\ advanced preprocessing outputs (advanced includes clitic segmentation)}{figure.6}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Top 15 morphological feature importances from XGBoost classifier. Verb count (\texttt  {num\_verbs}) is the most predictive feature, followed by conjunctions and imperative forms.}}{12}{figure.7}\protected@file@percent }
\newlabel{fig:morph_feature_importance}{{7}{12}{Top 15 morphological feature importances from XGBoost classifier. Verb count (\texttt {num\_verbs}) is the most predictive feature, followed by conjunctions and imperative forms}{figure.7}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces ROC curves comparing MARBERTv2, XGBoost (morphological features), and hybrid ensemble strategies. MARBERTv2 achieves AUC\nobreakspace  {}0.8886, while the confidence-based hybrid slightly improves to AUC\nobreakspace  {}0.8888.}}{13}{figure.8}\protected@file@percent }
\newlabel{fig:morph_roc_comparison}{{8}{13}{ROC curves comparing MARBERTv2, XGBoost (morphological features), and hybrid ensemble strategies. MARBERTv2 achieves AUC~0.8886, while the confidence-based hybrid slightly improves to AUC~0.8888}{figure.8}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Confusion matrices for four hybrid ensemble strategies: weighted averaging (0.4/0.6), stacking meta-learner, confidence-based selection, and adaptive weighted. The weighted approach achieves the highest F1 (0.8213).}}{14}{figure.9}\protected@file@percent }
\newlabel{fig:morph_ensemble_cm}{{9}{14}{Confusion matrices for four hybrid ensemble strategies: weighted averaging (0.4/0.6), stacking meta-learner, confidence-based selection, and adaptive weighted. The weighted approach achieves the highest F1 (0.8213)}{figure.9}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Left: Prediction analysis showing model agreement---57.4\% of samples are correctly classified by both MARBERTv2 and XGBoost. Right: Accuracy comparison showing the best ensemble (0.8314) slightly outperforms individual models.}}{14}{figure.10}\protected@file@percent }
\newlabel{fig:morph_prediction_analysis}{{10}{14}{Left: Prediction analysis showing model agreement---57.4\% of samples are correctly classified by both MARBERTv2 and XGBoost. Right: Accuracy comparison showing the best ensemble (0.8314) slightly outperforms individual models}{figure.10}{}}
\gdef \@abspage@last{15}
