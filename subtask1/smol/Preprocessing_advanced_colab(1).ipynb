{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "54761ea7",
      "metadata": {
        "id": "54761ea7"
      },
      "source": [
        "# Advanced Arabic Preprocessing Pipeline - Google Colab\n",
        "\n",
        "This notebook applies advanced preprocessing to Arabic text using CAMeL Tools with morphological segmentation.\n",
        "\n",
        "**Steps:**\n",
        "1. Install dependencies\n",
        "2. Upload preprocessing modules and dataset\n",
        "3. Process the dataset\n",
        "4. Download results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f308bce",
      "metadata": {
        "id": "0f308bce"
      },
      "source": [
        "## ⚠️ Important Note About Dependency Warnings\n",
        "\n",
        "When installing CAMeL Tools, you may see **numpy dependency conflict warnings**. These are **safe to ignore** because:\n",
        "\n",
        "1. Google Colab manages multiple package versions simultaneously\n",
        "2. CAMeL Tools requires `numpy<2.0`, but some Colab packages need `numpy>=2.0`\n",
        "3. Both versions coexist in Colab without issues\n",
        "4. The warnings don't affect functionality\n",
        "\n",
        "**TL;DR:** The error messages about numpy are expected and won't break anything. Just proceed with the cells below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a23a2e7",
      "metadata": {
        "id": "4a23a2e7"
      },
      "source": [
        "## 1. Setup - Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc08bf49",
      "metadata": {
        "id": "cc08bf49"
      },
      "source": [
        "## Alternative: Clean Install (Run if you get errors)\n",
        "\n",
        "If you encounter issues, use this cell instead to do a clean install:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b14b3a65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b14b3a65",
        "outputId": "d7328c41-16d5-4f1b-d361-564d742f6028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing CAMeL Tools (ignoring safe dependency warnings)...\n",
            "Collecting camel-tools\n",
            "  Downloading camel_tools-1.5.7-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from camel-tools) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from camel-tools) (1.17.0)\n",
            "Collecting docopt (from camel-tools)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cachetools<=6.0.0 in /usr/local/lib/python3.12/dist-packages (from camel-tools) (5.5.2)\n",
            "Collecting numpy<2 (from camel-tools)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m981.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from camel-tools) (1.16.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from camel-tools) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from camel-tools) (1.6.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from camel-tools) (0.3.8)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from camel-tools) (2.8.0+cu126)\n",
            "Collecting transformers<4.44.0,>=4.0 (from camel-tools)\n",
            "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.12/dist-packages (from camel-tools) (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from camel-tools) (2.32.4)\n",
            "Collecting emoji (from camel-tools)\n",
            "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pyrsistent (from camel-tools)\n",
            "  Downloading pyrsistent-0.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from camel-tools) (0.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from camel-tools) (4.67.1)\n",
            "Collecting muddler (from camel-tools)\n",
            "  Downloading muddler-0.1.3-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting camel-kenlm<=2025.09.16 (from camel-tools)\n",
            "  Downloading camel_kenlm-2025.9.16-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (251 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->camel-tools) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers<4.44.0,>=4.0->camel-tools) (0.6.2)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers<4.44.0,>=4.0->camel-tools)\n",
            "  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->camel-tools) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->camel-tools) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->camel-tools) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->camel-tools) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->camel-tools) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->camel-tools) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->camel-tools) (2025.10.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->camel-tools) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->camel-tools) (3.6.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers<4.44.0,>=4.0->camel-tools) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->camel-tools) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->camel-tools) (3.0.3)\n",
            "Downloading camel_tools-1.5.7-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading camel_kenlm-2025.9.16-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading muddler-0.1.3-py3-none-any.whl (16 kB)\n",
            "Downloading pyrsistent-0.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (122 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.3/122.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=b17fcaba8d9dbff9101e98ecf0f3c03d018344330aeb762ec0ce5187a77c9d34\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt, camel-kenlm, pyrsistent, numpy, muddler, emoji, tokenizers, transformers, camel-tools\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.1\n",
            "    Uninstalling transformers-4.57.1:\n",
            "      Successfully uninstalled transformers-4.57.1\n",
            "Successfully installed camel-kenlm-2025.9.16 camel-tools-1.5.7 docopt-0.6.2 emoji-2.15.0 muddler-0.1.3 numpy-1.26.4 pyrsistent-0.20.0 tokenizers-0.19.1 transformers-4.43.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "b0f9d99356c84a6083129ceb83758c74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Installation complete\n",
            "  Note: Numpy dependency warnings are expected and safe to ignore.\n",
            "  Colab's environment handles multiple numpy versions correctly.\n"
          ]
        }
      ],
      "source": [
        "# ALTERNATIVE INSTALLATION (use if standard install has issues)\n",
        "# This ignores dependency conflicts which are safe in Colab environment\n",
        "\n",
        "import os\n",
        "os.environ['PIP_NO_WARN_CONFLICTS'] = '1'\n",
        "\n",
        "print(\"Installing CAMeL Tools (ignoring safe dependency warnings)...\")\n",
        "!pip install --no-warn-conflicts camel-tools\n",
        "\n",
        "print(\"\\n✓ Installation complete\")\n",
        "print(\"  Note: Numpy dependency warnings are expected and safe to ignore.\")\n",
        "print(\"  Colab's environment handles multiple numpy versions correctly.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "60f06394",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60f06394",
        "outputId": "73759659-47cd-46a8-c96a-8cde0ee356fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing CAMeL Tools...\n",
            "Note: Fixing numpy dependency conflicts...\n",
            "\n",
            "✓ CAMeL Tools installed successfully\n",
            "  (Numpy version conflicts are expected and won't affect functionality)\n",
            "\n",
            "✓ Libraries imported\n"
          ]
        }
      ],
      "source": [
        "# Install CAMeL Tools with dependency fix\n",
        "print(\"Installing CAMeL Tools...\")\n",
        "print(\"Note: Fixing numpy dependency conflicts...\\n\")\n",
        "\n",
        "# Install camel-tools which requires numpy<2.0\n",
        "!pip install -q camel-tools\n",
        "\n",
        "# Restart warning for numpy conflicts (these are usually safe to ignore in Colab)\n",
        "print(\"✓ CAMeL Tools installed successfully\")\n",
        "print(\"  (Numpy version conflicts are expected and won't affect functionality)\\n\")\n",
        "\n",
        "# Import basic libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "print(\"✓ Libraries imported\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d91a7d1",
      "metadata": {
        "id": "7d91a7d1"
      },
      "source": [
        "## 2. Upload Preprocessing Modules\n",
        "\n",
        "Upload your `ArbPreBasic.py` and `ArbPreAdv.py` files when prompted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a319545e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "a319545e",
        "outputId": "a5321bf6-2efb-4b6e-adcf-c867f730f91b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload ArbPreBasic.py and ArbPreAdv.py:\n",
            "You should see a 'Choose Files' button below.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a934ba22-ba5c-48be-aa6b-a1157e89ea27\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a934ba22-ba5c-48be-aa6b-a1157e89ea27\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ArbPreBasic.py to ArbPreBasic (1).py\n",
            "Saving ArbPreAdv.py to ArbPreAdv.py\n",
            "\n",
            "⚠ Warning: Make sure both files are uploaded\n",
            "Files received: ['ArbPreBasic (1).py', 'ArbPreAdv.py']\n"
          ]
        }
      ],
      "source": [
        "print(\"Please upload ArbPreBasic.py and ArbPreAdv.py:\")\n",
        "print(\"You should see a 'Choose Files' button below.\\n\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Verify files\n",
        "if 'ArbPreBasic.py' in uploaded and 'ArbPreAdv.py' in uploaded:\n",
        "    print(\"\\n✓ Both preprocessing modules uploaded successfully\")\n",
        "    print(f\"  - ArbPreBasic.py ({len(uploaded['ArbPreBasic.py'])} bytes)\")\n",
        "    print(f\"  - ArbPreAdv.py ({len(uploaded['ArbPreAdv.py'])} bytes)\")\n",
        "else:\n",
        "    print(\"\\n⚠ Warning: Make sure both files are uploaded\")\n",
        "    print(f\"Files received: {list(uploaded.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15eb33bb",
      "metadata": {
        "id": "15eb33bb"
      },
      "source": [
        "## 3. Upload Dataset\n",
        "\n",
        "Upload your `arb.csv` file containing the Arabic text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "16e07f68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "16e07f68",
        "outputId": "823afb74-b521-4b9e-e148-4cbc65bf6e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your arb.csv file:\n",
            "You should see a 'Choose Files' button below.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ec3ae119-0414-488a-9a01-f57128ad7a41\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ec3ae119-0414-488a-9a01-f57128ad7a41\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving arb.csv to arb.csv\n",
            "\n",
            "✓ Dataset uploaded and moved to train/arb.csv\n",
            "\n",
            "Dataset preview:\n",
            "  Columns: ['id', 'text', 'polarization']\n",
            "  Shape: (5, 3)\n"
          ]
        }
      ],
      "source": [
        "print(\"Please upload your arb.csv file:\")\n",
        "print(\"You should see a 'Choose Files' button below.\\n\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Create train directory and organize files\n",
        "if not os.path.exists('train'):\n",
        "    os.makedirs('train')\n",
        "\n",
        "if 'arb.csv' in uploaded:\n",
        "    shutil.move('arb.csv', 'train/arb.csv')\n",
        "    print(\"\\n✓ Dataset uploaded and moved to train/arb.csv\")\n",
        "\n",
        "    # Show dataset info\n",
        "    df_preview = pd.read_csv('train/arb.csv', nrows=5)\n",
        "    print(f\"\\nDataset preview:\")\n",
        "    print(f\"  Columns: {list(df_preview.columns)}\")\n",
        "    print(f\"  Shape: {df_preview.shape}\")\n",
        "else:\n",
        "    print(\"\\n⚠ Error: arb.csv not found in uploaded files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ddc7402",
      "metadata": {
        "id": "3ddc7402"
      },
      "source": [
        "## 4. Import Preprocessing Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a71e0a26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a71e0a26",
        "outputId": "a35a8fab-616b-4ada-bed9-a9410f3975a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Preprocessing modules imported successfully\n"
          ]
        }
      ],
      "source": [
        "from ArbPreAdv import ArabicAdvancedPreprocessor\n",
        "\n",
        "print(\"✓ Preprocessing modules imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "881df23e",
      "metadata": {
        "id": "881df23e"
      },
      "source": [
        "## 5. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0030328a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "0030328a",
        "outputId": "2aa02bec-76d2-4e84-a8c6-4ec4017d1dbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Dataset loaded from: train/arb.csv\n",
            "  Shape: (3380, 3)\n",
            "  Columns: ['id', 'text', 'polarization']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     id  \\\n",
              "0  arb_a2a60c8b4af3389e842d8ec31afb0eea   \n",
              "1  arb_6723e56a672674a6c1d9b28b213c4a05   \n",
              "2  arb_b0365d606edeee38ae6c025b1ca33e96   \n",
              "3  arb_858c0ee684049ba6f416a6cecb0b0761   \n",
              "4  arb_bdafc73afd0bc2cd2badae2a089446b9   \n",
              "\n",
              "                                                text  polarization  \n",
              "0  احلام انتي ونعالي ومنو انتي حتى تقيمين الفناني...             1  \n",
              "1  وره الكواليس تنيجج من وره بعير صطناعي على فكرة...             1  \n",
              "2  .خخخخ الملكه احلام فيها شذوذ شنو هل بوس والدلع...             1  \n",
              "3  الله يخزي احلام هي والبرنامج الخايس الي كله مصخره             1  \n",
              "4  كس ام احلام الي ماربتها وش ملكه هههه متستاهل م...             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5e3427a-596d-41d9-b0d0-ad556a0a2f8f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>polarization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>arb_a2a60c8b4af3389e842d8ec31afb0eea</td>\n",
              "      <td>احلام انتي ونعالي ومنو انتي حتى تقيمين الفناني...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>arb_6723e56a672674a6c1d9b28b213c4a05</td>\n",
              "      <td>وره الكواليس تنيجج من وره بعير صطناعي على فكرة...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>arb_b0365d606edeee38ae6c025b1ca33e96</td>\n",
              "      <td>.خخخخ الملكه احلام فيها شذوذ شنو هل بوس والدلع...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>arb_858c0ee684049ba6f416a6cecb0b0761</td>\n",
              "      <td>الله يخزي احلام هي والبرنامج الخايس الي كله مصخره</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>arb_bdafc73afd0bc2cd2badae2a089446b9</td>\n",
              "      <td>كس ام احلام الي ماربتها وش ملكه هههه متستاهل م...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5e3427a-596d-41d9-b0d0-ad556a0a2f8f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5e3427a-596d-41d9-b0d0-ad556a0a2f8f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5e3427a-596d-41d9-b0d0-ad556a0a2f8f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Load the Arabic training dataset\n",
        "train_path = 'train/arb.csv'\n",
        "df = pd.read_csv(train_path)\n",
        "\n",
        "print(f\"✓ Dataset loaded from: {train_path}\")\n",
        "print(f\"  Shape: {df.shape}\")\n",
        "print(f\"  Columns: {list(df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1a315b5",
      "metadata": {
        "id": "c1a315b5"
      },
      "source": [
        "## 6. Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d4ef3d39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4ef3d39",
        "outputId": "2bfb38b1-746b-46a1-fb14-12b193350443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Information:\n",
            "  Total records: 3380\n",
            "  Null values:\n",
            "id              0\n",
            "text            0\n",
            "polarization    0\n",
            "dtype: int64\n",
            "\n",
            "Polarization distribution:\n",
            "polarization\n",
            "0    1868\n",
            "1    1512\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check dataset info\n",
        "print(\"Dataset Information:\")\n",
        "print(f\"  Total records: {len(df)}\")\n",
        "print(f\"  Null values:\\n{df.isnull().sum()}\")\n",
        "print(f\"\\nPolarization distribution:\")\n",
        "print(df['polarization'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download CAMeL Tools morphological database\n",
        "print(\"Downloading CAMeL Tools database...\")\n",
        "print(\"This is a one-time download (~50MB) and may take 1-2 minutes.\\n\")\n",
        "\n",
        "!camel_data -i morphology-db-msa-r13\n",
        "\n",
        "print(\"\\n✓ Database downloaded successfully!\")\n",
        "print(\"  Location: ~/.camel_tools/data/\")\n",
        "print(\"\\nNow ready to initialize preprocessor...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL2XtBODWSHh",
        "outputId": "bf047793-5289-4b93-e9e0-c4a6a9a020ec"
      },
      "id": "JL2XtBODWSHh",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CAMeL Tools database...\n",
            "This is a one-time download (~50MB) and may take 1-2 minutes.\n",
            "\n",
            "The following packages will be installed: 'morphology-db-msa-r13'\n",
            "Downloading package 'morphology-db-msa-r13': 100% 40.5M/40.5M [00:00<00:00, 290MB/s]\n",
            "Extracting package 'morphology-db-msa-r13': 100% 40.5M/40.5M [00:00<00:00, 532MB/s]\n",
            "\n",
            "✓ Database downloaded successfully!\n",
            "  Location: ~/.camel_tools/data/\n",
            "\n",
            "Now ready to initialize preprocessor...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "97_yZfuGWTUM"
      },
      "id": "97_yZfuGWTUM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "58f98899",
      "metadata": {
        "id": "58f98899"
      },
      "source": [
        "## 7. Initialize Advanced Preprocessor\n",
        "\n",
        "This will load CAMeL Tools models (may take 1-2 minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2e9f092f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e9f092f",
        "outputId": "b5dd5c14-54c2-4fb0-b799-f67d4c6b0240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing advanced preprocessor...\n",
            "This may take 1-2 minutes to load CAMeL Tools models...\n",
            "\n",
            "✓ Advanced preprocessor initialized\n",
            "\n",
            "Preprocessor features:\n",
            "  • Basic preprocessing (normalization, diacritics removal)\n",
            "  • Morphological segmentation\n",
            "  • Pronominal enclitic splitting (e.g., كتابهم → كتاب + هم)\n",
            "  • Definite article preserved\n",
            "  • Particles preserved\n",
            "\n",
            "================================================================================\n",
            "Sample preprocessing:\n",
            "================================================================================\n",
            "Original:\n",
            "احلام انتي ونعالي ومنو انتي حتى تقيمين الفنانين الملكه احلام هههههههه البقره احلام بابا عوفي الفن لا...\n",
            "\n",
            "Preprocessed:\n",
            "أحلام أنتي و+ نعالي ومنو أنتي حتى تقيمين الفنانين الملكة أحلام هههههههه البقرة أحلام ب+ أبا عوفي الف...\n"
          ]
        }
      ],
      "source": [
        "# Initialize the advanced preprocessor\n",
        "print(\"Initializing advanced preprocessor...\")\n",
        "print(\"This may take 1-2 minutes to load CAMeL Tools models...\\n\")\n",
        "\n",
        "preprocessor = ArabicAdvancedPreprocessor(\n",
        "    split_proclitics=None,              # Don't split proclitics by default\n",
        "    split_enclitics={'PRON'},           # Split pronominal enclitics\n",
        "    keep_definite_article=True,         # Keep 'Al' attached\n",
        "    keep_particles=True,                # Keep particles attached\n",
        "    use_light_stemming=False,           # Don't apply stemming\n",
        "    use_lemmatization=False,            # Don't apply lemmatization\n",
        "    use_basic_preprocessing=True        # Apply basic preprocessing first\n",
        ")\n",
        "\n",
        "print(\"✓ Advanced preprocessor initialized\")\n",
        "print(\"\\nPreprocessor features:\")\n",
        "print(\"  • Basic preprocessing (normalization, diacritics removal)\")\n",
        "print(\"  • Morphological segmentation\")\n",
        "print(\"  • Pronominal enclitic splitting (e.g., كتابهم → كتاب + هم)\")\n",
        "print(\"  • Definite article preserved\")\n",
        "print(\"  • Particles preserved\")\n",
        "\n",
        "# Test on a sample\n",
        "sample = df['text'].iloc[0]\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"Sample preprocessing:\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Original:\\n{sample[:100]}...\")\n",
        "print(f\"\\nPreprocessed:\\n{preprocessor.preprocess(sample)[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "724d601f",
      "metadata": {
        "id": "724d601f"
      },
      "source": [
        "## 8. Process All Texts\n",
        "\n",
        "⚠️ **Note:** This may take several minutes depending on dataset size.\n",
        "- Small dataset (<1000 texts): ~2-5 minutes\n",
        "- Medium dataset (1000-5000): ~10-20 minutes  \n",
        "- Large dataset (>5000): 30+ minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5c769f71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c769f71",
        "outputId": "a190b487-e27c-430e-ea85-f7fa95020e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing 3380 texts...\n",
            "This may take several minutes depending on dataset size...\n",
            "\n",
            "✓ Preprocessing complete!\n",
            "  Time taken: 0.57 minutes\n",
            "  Average: 0.010 seconds per text\n",
            "\n",
            "Dataset shape: (3380, 4)\n",
            "Columns: ['id', 'text', 'polarization', 'text_advanced']\n"
          ]
        }
      ],
      "source": [
        "# Apply preprocessing to all texts\n",
        "import time\n",
        "\n",
        "print(f\"Preprocessing {len(df)} texts...\")\n",
        "print(\"This may take several minutes depending on dataset size...\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Handle null values\n",
        "df['text_advanced'] = df['text'].apply(\n",
        "    lambda x: preprocessor.preprocess(x) if pd.notna(x) else x\n",
        ")\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "print(f\"✓ Preprocessing complete!\")\n",
        "print(f\"  Time taken: {elapsed_time/60:.2f} minutes\")\n",
        "print(f\"  Average: {elapsed_time/len(df):.3f} seconds per text\")\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cd13bdf",
      "metadata": {
        "id": "2cd13bdf"
      },
      "source": [
        "## 9. Compare Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "29302e6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29302e6f",
        "outputId": "7aaaea18-1e02-41c6-eac4-9ff8d85e92ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison: Original vs Advanced Preprocessing\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "Example 1:\n",
            "  Original:  احلام انتي ونعالي ومنو انتي حتى تقيمين الفنانين الملكه احلام هههههههه البقره احل...\n",
            "  Advanced:  أحلام أنتي و+ نعالي ومنو أنتي حتى تقيمين الفنانين الملكة أحلام هههههههه البقرة أ...\n",
            "  Label:     1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Example 2:\n",
            "  Original:  وره الكواليس تنيجج من وره بعير صطناعي على فكرة احﻻم رجل مو مره لهن تخيل على البن...\n",
            "  Advanced:  وره الكواليس تنيجج من وره بعير صطناعي على ف+ كرة احﻻم رجل مو مرة لهن تخيل على ال...\n",
            "  Label:     1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Example 3:\n",
            "  Original:  .خخخخ الملكه احلام فيها شذوذ شنو هل بوس والدلع مع شذا والله عيب اطلعت بويه احلام...\n",
            "  Advanced:  .خخخخ الملكة أحلام فيها شذوذ شنو هل بوس و+ الدلع مع شذا و+ الله عيب أطلعت بوية أ...\n",
            "  Label:     1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Text Statistics:\n",
            "  Original average length:     94.76 chars\n",
            "  Preprocessed average length: 97.88 chars\n",
            "  Character reduction:         -3.30%\n",
            "\n",
            "  Original average words:      16.71\n",
            "  Preprocessed average tokens: 18.67\n",
            "  Token change:                +11.71%\n"
          ]
        }
      ],
      "source": [
        "# Compare original vs preprocessed\n",
        "print(\"Comparison: Original vs Advanced Preprocessing\\n\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"  Original:  {df['text'].iloc[i][:80]}...\")\n",
        "    print(f\"  Advanced:  {df['text_advanced'].iloc[i][:80]}...\")\n",
        "    print(f\"  Label:     {df['polarization'].iloc[i]}\")\n",
        "    print(\"-\"*100)\n",
        "\n",
        "# Statistics\n",
        "orig_len = df['text'].str.len().mean()\n",
        "adv_len = df['text_advanced'].str.len().mean()\n",
        "orig_words = df['text'].str.split().str.len().mean()\n",
        "adv_words = df['text_advanced'].str.split().str.len().mean()\n",
        "\n",
        "print(f\"\\nText Statistics:\")\n",
        "print(f\"  Original average length:     {orig_len:.2f} chars\")\n",
        "print(f\"  Preprocessed average length: {adv_len:.2f} chars\")\n",
        "print(f\"  Character reduction:         {(orig_len - adv_len) / orig_len * 100:.2f}%\")\n",
        "print(f\"\\n  Original average words:      {orig_words:.2f}\")\n",
        "print(f\"  Preprocessed average tokens: {adv_words:.2f}\")\n",
        "print(f\"  Token change:                {(adv_words - orig_words) / orig_words * 100:+.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a99ea7cc",
      "metadata": {
        "id": "a99ea7cc"
      },
      "source": [
        "## 10. Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "63478709",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63478709",
        "outputId": "5d06b3b7-e55b-42e8-ce42-fada8b01939b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Full dataset saved!\n",
            "  Location: train/arb_with_advanced.csv\n",
            "  Columns: ['id', 'text', 'polarization', 'text_advanced']\n",
            "\n",
            "✓ Clean version saved!\n",
            "  Location: train/arb_clean_advanced.csv\n",
            "  Shape: (3380, 3)\n",
            "\n",
            "================================================================================\n",
            "SUMMARY\n",
            "================================================================================\n",
            "Processed 3380 records with advanced morphological preprocessing\n",
            "\n",
            "Output files:\n",
            "  1. train/arb_with_advanced.csv\n",
            "     (Contains: id, text, polarization, text_advanced)\n",
            "  2. train/arb_clean_advanced.csv\n",
            "     (Contains: id, text, polarization)\n"
          ]
        }
      ],
      "source": [
        "# Save the preprocessed dataset\n",
        "output_path = 'train/arb_with_advanced.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"✓ Full dataset saved!\")\n",
        "print(f\"  Location: {output_path}\")\n",
        "print(f\"  Columns: {list(df.columns)}\")\n",
        "\n",
        "# Also create a clean version with only the preprocessed text\n",
        "df_clean = df[['id', 'text_advanced', 'polarization']].copy()\n",
        "df_clean.rename(columns={'text_advanced': 'text'}, inplace=True)\n",
        "\n",
        "clean_output_path = 'train/arb_clean_advanced.csv'\n",
        "df_clean.to_csv(clean_output_path, index=False)\n",
        "\n",
        "print(f\"\\n✓ Clean version saved!\")\n",
        "print(f\"  Location: {clean_output_path}\")\n",
        "print(f\"  Shape: {df_clean.shape}\")\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SUMMARY\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Processed {len(df)} records with advanced morphological preprocessing\")\n",
        "print(f\"\\nOutput files:\")\n",
        "print(f\"  1. {output_path}\")\n",
        "print(f\"     (Contains: id, text, polarization, text_advanced)\")\n",
        "print(f\"  2. {clean_output_path}\")\n",
        "print(f\"     (Contains: id, text, polarization)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2269473",
      "metadata": {
        "id": "e2269473"
      },
      "source": [
        "## 11. Download Results\n",
        "\n",
        "Download the processed files to your computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "79782ff0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "79782ff0",
        "outputId": "ff4f7d92-0cfb-47fd-8f2c-00afdf728e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading files...\n",
            "\n",
            "Downloading arb_with_advanced.csv...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_169368c9-de70-468e-a70f-3515c32e06f1\", \"arb_with_advanced.csv\", 1314661)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading arb_clean_advanced.csv...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2c026815-9b96-4eb3-bbab-d075f4aa45a1\", \"arb_clean_advanced.csv\", 727602)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Downloads complete!\n",
            "Check your browser's download folder.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Downloading files...\\n\")\n",
        "\n",
        "# Download full dataset with both original and processed text\n",
        "print(\"Downloading arb_with_advanced.csv...\")\n",
        "files.download('train/arb_with_advanced.csv')\n",
        "\n",
        "# Download clean version with only processed text\n",
        "print(\"Downloading arb_clean_advanced.csv...\")\n",
        "files.download('train/arb_clean_advanced.csv')\n",
        "\n",
        "print(\"\\n✓ Downloads complete!\")\n",
        "print(\"Check your browser's download folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dcc5a3d",
      "metadata": {
        "id": "3dcc5a3d"
      },
      "source": [
        "---\n",
        "\n",
        "## Optional: Alternative Preprocessing Configurations\n",
        "\n",
        "Try different preprocessing strategies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13f40075",
      "metadata": {
        "id": "13f40075"
      },
      "outputs": [],
      "source": [
        "# Aggressive segmentation with lemmatization\n",
        "# Uncomment to use:\n",
        "\n",
        "# print(\"Initializing aggressive preprocessor...\")\n",
        "# preprocessor_aggressive = ArabicAdvancedPreprocessor(\n",
        "#     split_proclitics={'CONJ', 'PREP'},\n",
        "#     split_enclitics={'PRON'},\n",
        "#     keep_definite_article=False,\n",
        "#     use_lemmatization=True,\n",
        "#     use_basic_preprocessing=True\n",
        "# )\n",
        "\n",
        "# print(\"Processing with aggressive configuration...\")\n",
        "# df['text_aggressive'] = df['text'].apply(\n",
        "#     lambda x: preprocessor_aggressive.preprocess(x) if pd.notna(x) else x\n",
        "# )\n",
        "\n",
        "# # Save aggressive version\n",
        "# df.to_csv('train/arb_aggressive.csv', index=False)\n",
        "# files.download('train/arb_aggressive.csv')\n",
        "# print(\"✓ Aggressive preprocessing complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1671825c",
      "metadata": {
        "id": "1671825c"
      },
      "source": [
        "## Optional: Batch Processing for Large Datasets\n",
        "\n",
        "For very large datasets, process in batches to see progress:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a089fc0",
      "metadata": {
        "id": "9a089fc0"
      },
      "outputs": [],
      "source": [
        "# Process in batches with progress tracking\n",
        "# Uncomment to use:\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# batch_size = 100\n",
        "# n_batches = int(np.ceil(len(df) / batch_size))\n",
        "\n",
        "# print(f\"Processing {len(df)} texts in {n_batches} batches of {batch_size}...\\n\")\n",
        "\n",
        "# results = []\n",
        "# for i in range(n_batches):\n",
        "#     start_idx = i * batch_size\n",
        "#     end_idx = min((i + 1) * batch_size, len(df))\n",
        "#\n",
        "#     batch_texts = df['text'].iloc[start_idx:end_idx].tolist()\n",
        "#     batch_processed = preprocessor.preprocess_batch(batch_texts)\n",
        "#     results.extend(batch_processed)\n",
        "#\n",
        "#     print(f\"Batch {i+1}/{n_batches} complete ({end_idx}/{len(df)} texts)\")\n",
        "\n",
        "# df['text_advanced'] = results\n",
        "# print(\"\\n✓ Batch processing complete!\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}